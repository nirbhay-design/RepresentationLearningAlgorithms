environment: 
YAML: --config
==> SEED: 42
==> num_classes: 10
==> data_name: cifar10
==> data_params: {'algo': 'byol', 'data_dir': 'datasets/cifar10', 'batch_size': 512, 'num_workers': 3, 'image_size': 32}
==> return_logs: False
==> eval_every: 10
==> n_epochs: 800
==> n_epochs_mlp: 100
==> gpu_id: 6
==> opt: SGD
==> opt_params: {'lr': 0.4, 'momentum': 0.9, 'weight_decay': 0.0005}
==> schedular_params: {'T_max': 800, 'eta_min': 0.001}
==> mlp_opt: SGD
==> mlp_opt_params: {'lr': 0.1, 'momentum': 0.9}
==> model_params: {'model_name': 'resnet50', 'pretrained': False, 'proj_dim': 256, 'algo_type': 'byol', 'byol_hidden': 4096}
==> byol_pred_params: {'in_features': 256, 'hidden_dim': 4096, 'out_features': 256}
==> ema_tau: 0.99
==> mlp_type: linear
==> loss: byol
==> distributed: False
==> train_algo: byol
==> model_save_path: saved_models/byol.c10.r50.e800.pth
==> config: configs/byol.c10.yaml
--------------------------------------------------
===> using linear mlp
using optimizer: SGD
using optimizer: SGD
loss function: byol
# of Training Images: 50000
# of Testing Images: 10000
### byol Training begins
[GPU6] epochs: [1/800] train_loss_con: -3.201
[GPU6] epochs: [2/800] train_loss_con: -3.929
[GPU6] epochs: [3/800] train_loss_con: -3.937
