environment: 
YAML: configs/simclr.c100.yaml
==> SEED: 42
==> num_classes: 100
==> data_name: cifar100
==> data_params: {'algo': 'simclr', 'data_dir': 'datasets/cifar100', 'batch_size': 512, 'num_workers': 3, 'image_size': 32}
==> return_logs: False
==> eval_every: 10
==> n_epochs: 1000
==> n_epochs_mlp: 100
==> gpu_id: 2
==> opt: SGD
==> opt_params: {'lr': 0.5, 'momentum': 0.9, 'nesterov': True}
==> schedular_params: {'T_max': 1000, 'eta_min': 0.001}
==> mlp_opt: SGD
==> mlp_opt_params: {'lr': 0.01, 'momentum': 0.9, 'nesterov': True}
==> model_params: {'model_name': 'resnet50', 'pretrained': False, 'proj_dim': 128}
==> mlp_type: hidden
==> loss: simclr
==> loss_params: {'sim': 'cosine', 'tau': 0.5}
==> distributed: False
==> train_algo: simclr
--------------------------------------------------
===> using hiddin mlp
using optimizer: SGD
using optimizer: SGD
loss function: simclr
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
# of Training Images: 50000
# of Testing Images: 10000
### simclr Training begins
[GPU2] epochs: [1/1000] train_loss_con: 6.928
[GPU2] epochs: [2/1000] train_loss_con: 6.926
[GPU2] epochs: [3/1000] train_loss_con: 6.926
[GPU2] epochs: [4/1000] train_loss_con: 6.926
[GPU2] epochs: [5/1000] train_loss_con: 6.921
[GPU2] epochs: [6/1000] train_loss_con: 6.739
[GPU2] epochs: [7/1000] train_loss_con: 6.618
[GPU2] epochs: [8/1000] train_loss_con: 6.590
[GPU2] epochs: [9/1000] train_loss_con: 6.566
[GPU2] epochs: [10/1000] train_loss_con: 6.393
[GPU2] epochs: [11/1000] train_loss_con: 6.263
[GPU2] epochs: [12/1000] train_loss_con: 6.109
[GPU2] epochs: [13/1000] train_loss_con: 6.059
[GPU2] epochs: [14/1000] train_loss_con: 5.952
[GPU2] epochs: [15/1000] train_loss_con: 5.858
[GPU2] epochs: [16/1000] train_loss_con: 5.806
[GPU2] epochs: [17/1000] train_loss_con: 5.782
[GPU2] epochs: [18/1000] train_loss_con: 5.756
[GPU2] epochs: [19/1000] train_loss_con: 5.737
